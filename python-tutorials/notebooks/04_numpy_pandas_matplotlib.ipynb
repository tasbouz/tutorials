{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Tutorial - Numpy, Pandas & Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Numpy (a.k.a NUMeric PYthon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BASICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import numpy as np (so instead of writing numpy all the time, we write np)\n",
    "import numpy as np                                   \n",
    "\n",
    "# Basic numpy object: An 1D array (ONLY SAME TYPE OF ELEMENTS OTHERWISE EVERYTHING WILL TURN INTO STRINGS BY COERSION)\n",
    "# BE CAREFUL: Basic calculations ALWAYS elementwise in arrays (NOT POSSIBLE IN LISTS). Also elementwise between arrays!     \n",
    "foo = np.array([1,2,3,4])                           \n",
    "\n",
    "# A 2D array \n",
    "foo2 = np.array([[1,2,3,4],                          \n",
    "                 [5,6,7,8]])                         \n",
    "\n",
    "# The i'th element of the np.array. The first one is the 0th\n",
    "foo[i]                                          \n",
    "\n",
    "# The i'th element from the end of the np.array. The first (from the end) is 1\n",
    "foo[-i]                                              \n",
    "\n",
    "# Elements of the np.array from i up to j-1.\n",
    "foo[i:j]                                             \n",
    "\n",
    "# When something is missing, it means from the beggining (or the end). If both are missing prints the whole np.array\n",
    "foo[:j], foo[i:], foo[:]                             \n",
    "\n",
    "# Uses the condition in order to print only the right elements from the ARRAY\n",
    "foo[foo>2]                                           \n",
    "\n",
    "# Gives back all the positions of foo that are bigger than 2\n",
    "where(foo>2)                                         \n",
    "\n",
    "# For nD array, i picks the row ie: list, j picks the column ie: element of the list. Applies to all commands\n",
    "foo[i,j] \n",
    "\n",
    "# An attribute of the array: Shape: (#elements, #dimensions)\n",
    "foo.shape                                            \n",
    "\n",
    "# Shows the type of entries inside the array\n",
    "foo.dtype\n",
    "\n",
    "# Shows how many items are inside an array\n",
    "foo.size\n",
    "\n",
    "# Shows the dimensions of an array\n",
    "foo.ndim                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a random column vector\n",
    "a = np.random.rand(20,1)\n",
    "\n",
    "# Takes the exponential of every element (works with all functions available in numpy)\n",
    "exp_a = np.exp(a)\n",
    "\n",
    "# Find the dot products\n",
    "value = np.dot(a.T,a)\n",
    "matrix = np.dot(a,a.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pandas (Built on top of Numpy and uses Matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import pandas as pd (so instead of writing pandas all the time, we write pd)                                 \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# A Series. Since we have no keys, pandas use 0,1,2 for the index of each element\n",
    "foo = pd.Series([34,'tasos'])\n",
    "\n",
    "# Here we use keyes for the indices.\n",
    "foo = pd.Series({'age':34, 'name':'tasos'})           \n",
    "                                                      \n",
    "# STANDAR PYTHON SLICING FOR SERIES: foo[0], foo['age'], etc...\n",
    "# STANDAR PYTHON ACTIONS FOR SERIES: add lists, add to elements, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - DATAFRAME (Series combined together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Dataframe: Every dictionary a new row. Each key of dictionary a column\n",
    "df = pd.DataFrame([{'age':34, 'name':'tasos'},         \n",
    "                   {'age':43, 'name':'georgia'}])                        \n",
    "\n",
    "# Load data as Datafrane\n",
    "df = pd.read_table('path',                                 \n",
    "                   sep = ',',                   # Defines the seperator. Here is comma. Default of read_table: tab \n",
    "                   header = None,               # Define if there is a header or not. Here no header. Default of read_table: True. I can use a number to specify which row is the index      \n",
    "                   names = ['col1','col2'],     # Gives names to the columns from the list. MUST USE header = 0 for this one to work\n",
    "                   index = 'col1'               # Specify which column is the index. If none, creates an index by itself\n",
    "                   skiprows = 12,               # Line numbers to skip (0-indexed) or number of lines to skip (int) at the start of the file\n",
    "                   skipfooter = 12,             # Number of lines at bottom of file to skip (Unsupported with engine=’c’)\n",
    "                   usecols = [0,4]              # Choose specific columns from a file. Works also with name of the files\n",
    "                   nrows = 12)                  # Read only the first 12 rows\n",
    "                      \n",
    "# Saves the dataframe as a csv file named 'name' in the working directory\n",
    "pd.DataFrame().to_csv('name')                         \n",
    "\n",
    "\n",
    "# Selects the Column named 'col1' from Dataframe df. This object is a pandas series.\n",
    "# Must be used if there is a space in column name\n",
    "# Must be used if I want to define a new column\n",
    "# If the entries of the series are strings, we can do all the things we can do with strings. FIRST USE str. AND THEN THE METHOD OF A STRING\n",
    "df['col1']                                            \n",
    "                                                                                                         \n",
    "# Selects the Column named 'col1' from Dataframe df. This object is a pandas series.\n",
    "# If there is a space in column name, it cannot be used\n",
    "# It cannot be used for creating a new column\n",
    "# If the entries of the series are strings, we can do all the things we can do with strings\n",
    "df.col1                                               \n",
    "                                                      \n",
    "# Select Rows that satisfy the condition: df.col1 = 'hey'. Works for any condition that we can think.\n",
    "# For conditions: ==, !=, <, >, <=, >=\n",
    "# For multiple conditions: & (and), | (or)\n",
    "df[df.col1 = 'hey']                                   \n",
    "                                                      \n",
    "# For too many or's we can use the isin trick                                                    \n",
    "df[df.col1.isin(['hey', 'hey2'])]                    \n",
    "\n",
    "# Picks specific values using lables: index for rows, column name for columns\n",
    "# Use : or lists for many. We can also use conditions for rows\n",
    "df.loc['Greece', 'col1']                              \n",
    "                                                      \n",
    "# Same thing, picks specific values using positions by integers. Counts from the begining \n",
    "df.iloc[12,1]                                         \n",
    "\n",
    "# Same thing, picks specific values using both integers and column name. Best choice to be ok\n",
    "df.ix[12, 'col1']                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - BASIC METHODS & ATTRIBUTES OF DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# A tupple: (Rows, Columns)\n",
    "df.shape                                              \n",
    "\n",
    "# A list with the names of columns of df. Since they are strings, we can use all string methods\n",
    "df.columns\n",
    "\n",
    "# Informations on the index of the dataframe\n",
    "df.index \n",
    "\n",
    "# Renames the columns from names in list. MUST SPECIFY ALL OF THEM\n",
    "df.columns = ['a','b']\n",
    "\n",
    "# Shows the type of the values of each column in df\n",
    "df.dtypes                                             \n",
    "\n",
    "# Use column col1 as an index. BE CAREFUL: Not count as a column now. We can select indices only by using ix\n",
    "df.set_index('col1')\n",
    "\n",
    "# Puts the index back as a column, and then creates an abstract index\n",
    "df.reset_index()                                      \n",
    "\n",
    "# General info about df. memory_usage='deep' gives a very accurate description of memory usage\n",
    "df.info(memory_usage='deep') \n",
    "\n",
    "# Show the 10 first rows of df. Default value = 5\n",
    "df.head(10) \n",
    "\n",
    "# Show the 10 last rows of df. Default value = 5\n",
    "df.tail(10)\n",
    "\n",
    "# A dataframe containing all basic statistics as max, min, mean etc... per column\n",
    "df.describe() \n",
    "\n",
    "# Changes the df to any type we'll specify. Works with columns also. Works also with category\n",
    "df.astype()  \n",
    "\n",
    "# Shows the unique values of column col1. Returns a pandas series\n",
    "df.col1.unique()\n",
    "\n",
    "# Shows the number of unique values of column col1. Returns a pandas series\n",
    "df.col1.nunique() \n",
    "\n",
    "# Works also with columns of a dataframe i.e with pandas series\n",
    "df.col1.describe()  \n",
    "\n",
    "# Shows how many times unique values of col1 appear. \n",
    "# normalize = True, gives percentages instead of pure counts\n",
    "df.col1.value_counts(normalize = True)                \n",
    "\n",
    "# Groups the data w.r.t to col1. Now col1 turns to an extra index. After command we can choose max, min, mean etc.\n",
    "df.groupby('col1')                                    \n",
    "\n",
    "# Selects a lot of statistics in specific group.\n",
    "df.groupby('col1').agg(['min', 'max', 'mean']).       \n",
    "\n",
    "# Deletes from df the column named 'col1'. We can use index of column. Eg: 1. axis=1 means columns. inplace=True means do it in the original dataframe\n",
    "df.drop('col1', axis=1, inplace=True)                 \n",
    "\n",
    "# Deletes from df the rows with index 1 and 2. axis=0 means rows. inplace=True means do it in the original dataframe\n",
    "df.drop([1,2], axis=0, inplace=True)                  \n",
    "\n",
    "# Renames columns of dataframe. Dictionary: Key = Old Name, Value = New Name.\n",
    "# NO NEED TO SPECIFY ALL OF THEM. Just use the columns you want to change.\n",
    "df.rename({'old': 'new'})                             \n",
    "                                                      \n",
    "# Returns the df sorted by the values of column 'col1'. USE A LIST OF COLUMNS FOR MULTIPLE SORTING\n",
    "df.sort_values('col1')                                \n",
    "\n",
    "# Sorts the rows of column 'col1'. Returns a pandas series. By default ascending = True. DOES NOT CHANGE THE df.col1\n",
    "df.col1.sort_values(ascending = False)                \n",
    "\n",
    "# Changes the type of the col1 to float. Works with all types. object means string\n",
    "df.col1.astype(float)                                 \n",
    "\n",
    "# iterrows(): A way for iterrate through the dataframe. \n",
    "for index, row in df.iterrows():                      \n",
    "    print(index, row.col1, row.col2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - TIMESERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Timestamp\n",
    "ts = pd.Timestamp('2016 Jul 1 10:00:00')\n",
    "\n",
    "# Dates (Works with: '2016 Jul 1', '7/1/2016', '1/7/2016', 'July 1, 2016', '2016-07-01', '2016/07/01')\n",
    "dt = pd.date_range('2016 Jul 1 10:00:00', periods = 10, freq = 'D')\n",
    "dt = pd.date_range('2016 Jul 1 10:00:00', '2016 Jul 10 10:00:00', freq = 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot as plt (so instead of writing matplotlib.pyplot all the time, we write plt)                                 \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Shows the plot that we created. Always at the end of the code\n",
    "plt.show()                                                   \n",
    "\n",
    "# Arranges the details of the graph\n",
    "plt.figure(figsize = (1,1))                 # Sets the size of the figure)                                         # \n",
    "\n",
    "# Basic plot of x and y. \n",
    "plt.plot(x, y,                                               \n",
    "         label = 'First Plot',              # The label that characterizes this plot\n",
    "         color = 'red',                     # The color of the line\n",
    "         linewidth = 1.0,                   # The width of the line, measured in pixels    \n",
    "         linestyle = '-')                   # The style of the line, i.e what symbol will be used in order to create the graph                      \n",
    "\n",
    "# Another plot (on the same picture). Use another label for distinction\n",
    "plt.plot(x2, y2, label = 'Second Plot')                      \n",
    "\n",
    "# Bar Plot\n",
    "plt.bar(x3, y3, label = 'Bar Plot')\n",
    "\n",
    "# Histogram Plot of x (Measures the frequency of entries in x)\n",
    "plt.hist(x,\n",
    "         bins = 30)                          # Number of bins on the plot. We can also give a list of specific bins\n",
    "\n",
    "# Scatter Plot\n",
    "plt.scatter(x3, y3, label = 'Scatter Plot')\n",
    "\n",
    "# Stack Plot: One x-axis a lot of data in y axis.\n",
    "plt.stackplot(x, y1,y2,y3, colors = [])\n",
    "\n",
    "# Pie Chart: One x axis, shows percentage as coverage\n",
    "plt.pie(x, labels=[], colors=[],\n",
    "        startangle=90                         # Starting angle (here 90 degrees)\n",
    "        shadow = True                         # Adds a shadow\n",
    "        explode = (0, 0.1, 0)                 # Explodes slices of pie. Define which and how in the parenthesis. (here only the second one by 0.1)\n",
    "        autopct = '%1.1f%%'                   # Adds percentages on the slices of the pie\n",
    "\n",
    "# Title of plot\n",
    "plt.title('Graph Title\\nSecond Line')\n",
    "        \n",
    "# Name of x-axis\n",
    "plt.xlabel('x-axis')\n",
    "        \n",
    "# Name of y-axis       \n",
    "plt.ylabel('y-axis')                                         \n",
    "\n",
    "# Uses the labels of plots and creates a legend.       \n",
    "plt.legend(loc = 'upper left',                  # Sets the position of the legend.\n",
    "           frameon = False)                     # Sets if there is a frame covering legend or not             \n",
    "\n",
    "# The limits of x-axis. First list picks points, second list gives specific names\n",
    "plt.xlim([-1.0, 1.0],['hey', 'hey'])  \n",
    "        \n",
    "# Choose specific points to show on x-axis, not everything\n",
    "plt.xticks(np.linspace(1, endpoint = True)) \n",
    "        \n",
    "# The limits of y-axis. First list picks points, second list gives specific names\n",
    "plt.ylim([-1.0, 1.0], ['hey', 'hey'])  \n",
    "        \n",
    "# Choose specific points to show on y-axis, not everything\n",
    "plt.yticks(np.linspace(1, endpoint = True))                  \n",
    "\n",
    "# Start manipulating the axes\n",
    "ax = plt.gca() \n",
    "        \n",
    "# Manipulating spines (There are 4: top, bottom, right, left)\n",
    "ax.spines['top']  \n",
    "        \n",
    "# Setting the color. By None we just vasish it\n",
    "ax.spines['top'].set_color('None')\n",
    "        \n",
    "# In which spine will the ticks appear on x-axis\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "        \n",
    "# Specifies the position of spines. The tuple says, 0 w.r.t to the data\n",
    "ax.spines['top'].set_position(('data',0))                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
